{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marumarukun/pj/compe/atma_18/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_number: '007'\n",
      "run_time: base\n",
      "data:\n",
      "  input_root: ../../data/input\n",
      "  train_path: ../../data/input/train_features.csv\n",
      "  test_path: ../../data/input/test_features.csv\n",
      "  sample_submission_path: ../../data/input/sample_submission.csv\n",
      "  img_root: ../../data/input/images\n",
      "  json_root: ../../data/input/traffic_lights\n",
      "  depth_root: ../../data/input/depth\n",
      "  output_root: ../../data/output\n",
      "  results_root: ../../results\n",
      "  results_path: ../../results/007/base\n",
      "seed: 319\n",
      "n_splits: 4\n",
      "target_cols:\n",
      "- x_0\n",
      "- y_0\n",
      "- z_0\n",
      "- x_1\n",
      "- y_1\n",
      "- z_1\n",
      "- x_2\n",
      "- y_2\n",
      "- z_2\n",
      "- x_3\n",
      "- y_3\n",
      "- z_3\n",
      "- x_4\n",
      "- y_4\n",
      "- z_4\n",
      "- x_5\n",
      "- y_5\n",
      "- z_5\n",
      "cnn:\n",
      "  model_name: tf_efficientnet_b0_ns\n",
      "  size: 128\n",
      "  pretrained: true\n",
      "  in_chans: 20\n",
      "  target_size: 18\n",
      "  lr: 0.001\n",
      "  num_epochs: 20\n",
      "  batch_size: 32\n",
      "\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pytz\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from omegaconf import OmegaConf\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "from src.config import cfg\n",
    "from src.dir import create_dir\n",
    "from src.seed import seed_everything\n",
    "\n",
    "cfg.exp_number = Path().resolve().name\n",
    "print(OmegaConf.to_yaml(cfg, resolve=True))\n",
    "\n",
    "seed_everything(cfg.seed)\n",
    "pl.Config.set_fmt_str_lengths(1000)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "train = pl.read_csv(cfg.data.train_path, try_parse_dates=True)\n",
    "test = pl.read_csv(cfg.data.test_path, try_parse_dates=True)\n",
    "sample_submission = pl.read_csv(cfg.data.sample_submission_path, try_parse_dates=True)\n",
    "\n",
    "# データの結合(label encoding用)\n",
    "train_test = pl.concat([train, test], how=\"diagonal\")\n",
    "\n",
    "# scene列を作成 → これでGroupKFoldする\n",
    "train = train.with_columns(pl.col(\"ID\").str.split(\"_\").list[0].alias(\"scene\"))\n",
    "test = test.with_columns(pl.col(\"ID\").str.split(\"_\").list[0].alias(\"scene\"))\n",
    "\n",
    "# CV\n",
    "gkf = GroupKFold(n_splits=cfg.n_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 31)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ID</th><th>vEgo</th><th>aEgo</th><th>steeringAngleDeg</th><th>steeringTorque</th><th>brake</th><th>brakePressed</th><th>gas</th><th>gasPressed</th><th>gearShifter</th><th>leftBlinker</th><th>rightBlinker</th><th>x_0</th><th>y_0</th><th>z_0</th><th>x_1</th><th>y_1</th><th>z_1</th><th>x_2</th><th>y_2</th><th>z_2</th><th>x_3</th><th>y_3</th><th>z_3</th><th>x_4</th><th>y_4</th><th>z_4</th><th>x_5</th><th>y_5</th><th>z_5</th><th>scene</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>bool</td><td>f64</td><td>bool</td><td>str</td><td>bool</td><td>bool</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>&quot;00066be8e20318869c38c66be466631a_320&quot;</td><td>5.701526</td><td>1.538456</td><td>-2.165777</td><td>-139.0</td><td>0.0</td><td>false</td><td>0.25</td><td>true</td><td>&quot;drive&quot;</td><td>false</td><td>false</td><td>2.82959</td><td>0.032226</td><td>0.045187</td><td>6.231999</td><td>0.065895</td><td>0.107974</td><td>9.785009</td><td>0.124972</td><td>0.203649</td><td>13.485472</td><td>0.163448</td><td>0.302818</td><td>17.574227</td><td>0.174289</td><td>0.406331</td><td>21.951269</td><td>0.199503</td><td>0.485079</td><td>&quot;00066be8e20318869c38c66be466631a&quot;</td></tr><tr><td>&quot;00066be8e20318869c38c66be466631a_420&quot;</td><td>11.176292</td><td>0.279881</td><td>-11.625697</td><td>-44.0</td><td>0.0</td><td>false</td><td>0.0</td><td>false</td><td>&quot;drive&quot;</td><td>false</td><td>true</td><td>4.970268</td><td>-0.007936</td><td>0.005028</td><td>10.350489</td><td>-0.032374</td><td>-0.020701</td><td>15.770054</td><td>0.084073</td><td>0.008645</td><td>21.132415</td><td>0.391343</td><td>0.036335</td><td>26.316489</td><td>0.843124</td><td>0.065</td><td>31.383814</td><td>1.42507</td><td>0.073083</td><td>&quot;00066be8e20318869c38c66be466631a&quot;</td></tr><tr><td>&quot;00066be8e20318869c38c66be466631a_520&quot;</td><td>10.472548</td><td>0.231099</td><td>-2.985105</td><td>-132.0</td><td>0.0</td><td>false</td><td>0.18</td><td>true</td><td>&quot;drive&quot;</td><td>false</td><td>false</td><td>4.815701</td><td>-0.000813</td><td>0.017577</td><td>10.153522</td><td>-0.0278</td><td>0.026165</td><td>15.446539</td><td>-0.155987</td><td>0.040397</td><td>20.61816</td><td>-0.356932</td><td>0.058765</td><td>25.677387</td><td>-0.576985</td><td>0.102859</td><td>30.460033</td><td>-0.841894</td><td>0.152889</td><td>&quot;00066be8e20318869c38c66be466631a&quot;</td></tr><tr><td>&quot;000fb056f97572d384bae4f5fc1e0f28_120&quot;</td><td>6.055565</td><td>-0.117775</td><td>7.632668</td><td>173.0</td><td>0.0</td><td>false</td><td>0.0</td><td>false</td><td>&quot;drive&quot;</td><td>false</td><td>false</td><td>2.812608</td><td>0.033731</td><td>0.0059</td><td>5.975378</td><td>0.137848</td><td>0.01621</td><td>9.186793</td><td>0.322997</td><td>0.031626</td><td>12.37311</td><td>0.603145</td><td>0.031858</td><td>15.703514</td><td>0.960717</td><td>0.043479</td><td>19.311182</td><td>1.374655</td><td>0.058754</td><td>&quot;000fb056f97572d384bae4f5fc1e0f28&quot;</td></tr><tr><td>&quot;000fb056f97572d384bae4f5fc1e0f28_20&quot;</td><td>3.316744</td><td>1.276733</td><td>-31.725477</td><td>-114.0</td><td>0.0</td><td>false</td><td>0.255</td><td>true</td><td>&quot;drive&quot;</td><td>false</td><td>false</td><td>1.55186</td><td>-0.041849</td><td>-0.008847</td><td>3.675162</td><td>-0.125189</td><td>-0.013725</td><td>6.113567</td><td>-0.239161</td><td>-0.012887</td><td>8.770783</td><td>-0.381813</td><td>-0.003898</td><td>11.619313</td><td>-0.554488</td><td>0.011393</td><td>14.657048</td><td>-0.7788</td><td>0.044243</td><td>&quot;000fb056f97572d384bae4f5fc1e0f28&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 31)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬──────────┬───────────┐\n",
       "│ ID        ┆ vEgo      ┆ aEgo      ┆ steeringA ┆ … ┆ x_5       ┆ y_5       ┆ z_5      ┆ scene     │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ngleDeg   ┆   ┆ ---       ┆ ---       ┆ ---      ┆ ---       │\n",
       "│ str       ┆ f64       ┆ f64       ┆ ---       ┆   ┆ f64       ┆ f64       ┆ f64      ┆ str       │\n",
       "│           ┆           ┆           ┆ f64       ┆   ┆           ┆           ┆          ┆           │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪══════════╪═══════════╡\n",
       "│ 00066be8e ┆ 5.701526  ┆ 1.538456  ┆ -2.165777 ┆ … ┆ 21.951269 ┆ 0.199503  ┆ 0.485079 ┆ 00066be8e │\n",
       "│ 20318869c ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆ 20318869c │\n",
       "│ 38c66be46 ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆ 38c66be46 │\n",
       "│ 6631a_320 ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆ 6631a     │\n",
       "│ 00066be8e ┆ 11.176292 ┆ 0.279881  ┆ -11.62569 ┆ … ┆ 31.383814 ┆ 1.42507   ┆ 0.073083 ┆ 00066be8e │\n",
       "│ 20318869c ┆           ┆           ┆ 7         ┆   ┆           ┆           ┆          ┆ 20318869c │\n",
       "│ 38c66be46 ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆ 38c66be46 │\n",
       "│ 6631a_420 ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆ 6631a     │\n",
       "│ 00066be8e ┆ 10.472548 ┆ 0.231099  ┆ -2.985105 ┆ … ┆ 30.460033 ┆ -0.841894 ┆ 0.152889 ┆ 00066be8e │\n",
       "│ 20318869c ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆ 20318869c │\n",
       "│ 38c66be46 ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆ 38c66be46 │\n",
       "│ 6631a_520 ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆ 6631a     │\n",
       "│ 000fb056f ┆ 6.055565  ┆ -0.117775 ┆ 7.632668  ┆ … ┆ 19.311182 ┆ 1.374655  ┆ 0.058754 ┆ 000fb056f │\n",
       "│ 97572d384 ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆ 97572d384 │\n",
       "│ bae4f5fc1 ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆ bae4f5fc1 │\n",
       "│ e0f28_120 ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆ e0f28     │\n",
       "│ 000fb056f ┆ 3.316744  ┆ 1.276733  ┆ -31.72547 ┆ … ┆ 14.657048 ┆ -0.7788   ┆ 0.044243 ┆ 000fb056f │\n",
       "│ 97572d384 ┆           ┆           ┆ 7         ┆   ┆           ┆           ┆          ┆ 97572d384 │\n",
       "│ bae4f5fc1 ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆ bae4f5fc1 │\n",
       "│ e0f28_20  ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆ e0f28     │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴──────────┴───────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ拡張\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform():\n",
    "    return A.ReplayCompose(\n",
    "        [\n",
    "            A.Resize(cfg.cnn.size, cfg.cnn.size),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_valid_transform():\n",
    "    return A.ReplayCompose(\n",
    "        [\n",
    "            A.Resize(cfg.cnn.size, cfg.cnn.size),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 信号機マスク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficLightMaskGenerator:\n",
    "    TRAFFIC_LIGHT_CLASSES = [\"green\", \"yellow\", \"red\", \"straight\", \"left\", \"right\", \"empty\", \"other\"]\n",
    "\n",
    "    def __init__(self, image_size: list[int, int] | int | None = None):\n",
    "        self.original_size = (128, 64)  # (width, height)\n",
    "\n",
    "        if isinstance(image_size, list):\n",
    "            self.image_size = (image_size[1], image_size[0])\n",
    "        elif isinstance(image_size, int):\n",
    "            self.image_size = (image_size, image_size)\n",
    "        else:\n",
    "            self.image_size = self.original_size\n",
    "\n",
    "        self.scale = (self.image_size[0] / self.original_size[0], self.image_size[1] / self.original_size[1])\n",
    "\n",
    "        self.class_to_index = {cls: idx for idx, cls in enumerate(self.TRAFFIC_LIGHT_CLASSES)}\n",
    "\n",
    "    def scale_bbox(self, bbox):\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        return [x1 * self.scale[0], y1 * self.scale[1], x2 * self.scale[0], y2 * self.scale[1]]\n",
    "\n",
    "    def _convert_coordinate(self, coord, max_size):\n",
    "        \"\"\"座標を適切な範囲に収める\"\"\"\n",
    "        return max(0, min(int(round(coord)), max_size - 1))\n",
    "\n",
    "    def generate_masks(self, traffic_lights_json):\n",
    "        # PosixPathオブジェクトを文字列に変換\n",
    "        if isinstance(traffic_lights_json, Path):\n",
    "            traffic_lights_json = str(traffic_lights_json)\n",
    "\n",
    "        traffic_lights = (\n",
    "            json.load(open(traffic_lights_json)) if isinstance(traffic_lights_json, str) else traffic_lights_json\n",
    "        )\n",
    "\n",
    "        masks = np.zeros((self.image_size[1], self.image_size[0], len(self.TRAFFIC_LIGHT_CLASSES)), dtype=np.float32)\n",
    "\n",
    "        for light in traffic_lights:\n",
    "            class_idx = self.class_to_index[light[\"class\"]]\n",
    "            scaled_bbox = self.scale_bbox(light[\"bbox\"])\n",
    "\n",
    "            # 座標を適切な範囲に収める\n",
    "            x1 = self._convert_coordinate(scaled_bbox[0], self.image_size[0])\n",
    "            y1 = self._convert_coordinate(scaled_bbox[1], self.image_size[1])\n",
    "            x2 = self._convert_coordinate(scaled_bbox[2], self.image_size[0])\n",
    "            y2 = self._convert_coordinate(scaled_bbox[3], self.image_size[1])\n",
    "\n",
    "            masks[y1 : y2 + 1, x1 : x2 + 1, class_idx] = 1.0\n",
    "\n",
    "        return masks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, json_dir, depth_dir, transform=None, is_train=True):\n",
    "        self.df = df\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.json_dir = Path(json_dir)\n",
    "        self.depth_dir = Path(depth_dir)\n",
    "        self.is_train = is_train\n",
    "\n",
    "        # オリジナル画像用の変換処理\n",
    "        if transform is None:\n",
    "            self.transform = A.ReplayCompose(\n",
    "                [\n",
    "                    A.Resize(cfg.cnn.size, cfg.cnn.size),\n",
    "                    A.Normalize(\n",
    "                        mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225],\n",
    "                    ),\n",
    "                    ToTensorV2(),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            self.transform = transform\n",
    "\n",
    "        # Depth Map用の変換処理\n",
    "        self.depth_transform = A.ReplayCompose(\n",
    "            [\n",
    "                A.Resize(cfg.cnn.size, cfg.cnn.size),\n",
    "                A.Normalize(mean=[0.5], std=[0.5]),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.target_cols = cfg.target_cols\n",
    "        self.mask_generator = TrafficLightMaskGenerator(cfg.cnn.size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df[idx]\n",
    "        img_folder = self.img_dir / row[\"ID\"].item()\n",
    "        depth_folder = self.depth_dir / row[\"ID\"].item()\n",
    "        json_path = self.json_dir / f\"{row['ID'].item()}.json\"\n",
    "\n",
    "        # 3枚の画像を読み込み\n",
    "        img_names = [\"image_t-1.0.png\", \"image_t-0.5.png\", \"image_t.png\"]\n",
    "        imgs = []\n",
    "        depths = []\n",
    "\n",
    "        for img_name in img_names:\n",
    "            # オリジナル画像の読み込み\n",
    "            img_path = img_folder / img_name\n",
    "            img = cv2.imread(str(img_path))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            imgs.append(img)\n",
    "\n",
    "            # Depth Mapの読み込み\n",
    "            depth_path = depth_folder / img_name\n",
    "            depth = cv2.imread(str(depth_path), cv2.IMREAD_GRAYSCALE)\n",
    "            depths.append(depth)\n",
    "\n",
    "        # オリジナル画像の変換\n",
    "        if self.transform:\n",
    "            replay = None\n",
    "            transformed_imgs = []\n",
    "\n",
    "            for img in imgs:\n",
    "                if replay is None:\n",
    "                    # 最初の画像に対して変換を実行し、replayを保存\n",
    "                    transformed = self.transform(image=img)\n",
    "                    replay = transformed[\"replay\"]\n",
    "                else:\n",
    "                    # 2枚目以降は保存したreplayを使用\n",
    "                    transformed = A.ReplayCompose.replay(replay, image=img)\n",
    "                transformed_imgs.append(transformed[\"image\"])\n",
    "\n",
    "        # Depth Mapの変換\n",
    "        transformed_depths = []\n",
    "        for depth in depths:\n",
    "            transformed_depth = self.depth_transform(image=depth)\n",
    "            transformed_depths.append(transformed_depth[\"image\"])\n",
    "\n",
    "        # オリジナル画像をチャネル方向に結合 (C*3, H, W)\n",
    "        img_tensor = torch.cat(transformed_imgs, dim=0)\n",
    "\n",
    "        # Depth Mapをチャネル方向に結合 (3, H, W)\n",
    "        depth_tensor = torch.cat(transformed_depths, dim=0)\n",
    "\n",
    "        # 信号機マスクの生成\n",
    "        mask = self.mask_generator.generate_masks(json_path)\n",
    "        mask_tensor = torch.from_numpy(mask).permute(2, 0, 1)  # (8, H, W)\n",
    "\n",
    "        # 画像, Depth Map, 信号機マスクをチャネル方向に結合 (C*3+3+8=20, H, W)\n",
    "        combined_tensor = torch.cat([img_tensor, depth_tensor, mask_tensor], dim=0)\n",
    "\n",
    "        # ターゲットの準備\n",
    "        if self.is_train:\n",
    "            target = torch.tensor(row[self.target_cols].to_numpy(), dtype=torch.float32).squeeze(0)\n",
    "            return combined_tensor, target\n",
    "        else:\n",
    "            return combined_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GeM(nn.Module):\n",
    "#     def __init__(self, p=3, eps=1e-6, p_trainable=True):\n",
    "#         super().__init__()\n",
    "#         if p_trainable:\n",
    "#             self.p = nn.Parameter(torch.ones(1) * p)\n",
    "#         else:\n",
    "#             self.p = p\n",
    "#         self.eps = eps\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.clamp(min=self.eps).pow(self.p)\n",
    "#         x = F.adaptive_avg_pool2d(x, 1)\n",
    "#         x = x.pow(1.0 / self.p)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, pretrained=False, target_size=None, model_name=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = timm.create_model(\n",
    "            cfg.model_name,\n",
    "            pretrained=cfg.pretrained,\n",
    "            num_classes=0,\n",
    "            in_chans=cfg.in_chans,\n",
    "            # global_pool=\"\",\n",
    "        )\n",
    "\n",
    "        self.n_features = self.encoder.num_features\n",
    "        # self.pool = GeM(p=3, eps=1e-6, p_trainable=True)\n",
    "\n",
    "        self.target_size = cfg.target_size if target_size is None else target_size\n",
    "\n",
    "        self.fc = nn.Sequential(nn.Linear(self.n_features, self.target_size))\n",
    "\n",
    "    def get_embedding(self, image):\n",
    "        with torch.no_grad():\n",
    "            feature = self.encoder(image)\n",
    "        return feature\n",
    "\n",
    "    def forward(self, image):\n",
    "        feature = self.encoder(image)\n",
    "        # feature = self.pool(feature).reshape(feature.size(0), -1)\n",
    "        output = self.fc(feature)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marumarukun/pj/compe/atma_18/.venv/lib/python3.12/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
      "  model = create_fn(\n"
     ]
    }
   ],
   "source": [
    "model = CustomModel(cfg.cnn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "if DEBUG:\n",
    "    cfg.cnn.num_epochs = 1\n",
    "    train = train.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory created: ../../results/007/20241123_001536\n",
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marumarukun/pj/compe/atma_18/.venv/lib/python3.12/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
      "  model = create_fn(\n",
      "100%|██████████| 1017/1017 [04:38<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Valid Loss: 0.9334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:40<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Valid Loss: 0.8504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:41<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Valid Loss: 0.8447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:43<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Valid Loss: 0.7538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:39<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Valid Loss: 0.7462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:38<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Valid Loss: 0.6992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:35<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Valid Loss: 0.6803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:36<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Valid Loss: 0.6501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:36<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Valid Loss: 0.6350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:38<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Valid Loss: 0.6227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:34<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Valid Loss: 0.6302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:36<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Valid Loss: 0.6306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:36<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Valid Loss: 0.6062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:38<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Valid Loss: 0.6069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:36<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Valid Loss: 0.6029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:37<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Valid Loss: 0.5971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:38<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Valid Loss: 0.5977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:38<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Valid Loss: 0.5976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:34<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Valid Loss: 0.5957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:32<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Valid Loss: 0.5976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1568158/725687470.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f\"{cfg.data.results_path}/model_fold{fold}.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:30<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Valid Loss: 1.0416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:29<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Valid Loss: 1.0433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:27<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Valid Loss: 0.7790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:30<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Valid Loss: 0.7429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:29<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Valid Loss: 0.7457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:30<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Valid Loss: 0.6924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:30<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Valid Loss: 0.6530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:30<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Valid Loss: 0.6613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:31<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Valid Loss: 0.6444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:27<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Valid Loss: 0.6270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:27<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Valid Loss: 0.6020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:26<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Valid Loss: 0.6084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:26<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Valid Loss: 0.5898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:29<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Valid Loss: 0.5947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:26<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Valid Loss: 0.5829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:27<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Valid Loss: 0.5821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:25<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Valid Loss: 0.5805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:28<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Valid Loss: 0.5784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:27<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Valid Loss: 0.5806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:29<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Valid Loss: 0.5801\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:31<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Valid Loss: 0.9377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:32<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Valid Loss: 0.8974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:27<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Valid Loss: 0.8181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:32<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Valid Loss: 0.7331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:30<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Valid Loss: 0.7236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:32<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Valid Loss: 0.7298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:30<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Valid Loss: 0.6916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:32<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Valid Loss: 0.8243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:31<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Valid Loss: 0.6342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:31<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Valid Loss: 0.6334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:29<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Valid Loss: 0.6294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:31<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Valid Loss: 0.6120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:33<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Valid Loss: 0.5956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:31<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Valid Loss: 0.5951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:31<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Valid Loss: 0.5892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:32<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Valid Loss: 0.5874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:32<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Valid Loss: 0.5904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:31<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Valid Loss: 0.5860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:31<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Valid Loss: 0.5887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:30<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Valid Loss: 0.5874\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:35<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Valid Loss: 1.1139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:32<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Valid Loss: 0.8644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:32<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Valid Loss: 0.7633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:31<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Valid Loss: 0.7288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:32<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Valid Loss: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:31<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Valid Loss: 0.6877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:31<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Valid Loss: 0.6617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:31<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Valid Loss: 0.6402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:31<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Valid Loss: 0.6296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:31<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Valid Loss: 0.6389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:32<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Valid Loss: 0.6107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:32<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Valid Loss: 0.6047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:32<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Valid Loss: 0.5941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:33<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Valid Loss: 0.5997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:34<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Valid Loss: 0.6081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:34<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Valid Loss: 0.5887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:32<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Valid Loss: 0.5870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:31<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Valid Loss: 0.5885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:31<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Valid Loss: 0.5865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [04:32<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Valid Loss: 0.5865\n",
      "CV Score: 0.7972\n"
     ]
    }
   ],
   "source": [
    "# 実験結果格納用のディレクトリを作成\n",
    "japan_tz = pytz.timezone(\"Asia/Tokyo\")\n",
    "cfg.run_time = datetime.now(japan_tz).strftime(\"%Y%m%d_%H%M%S\")\n",
    "create_dir(cfg.data.results_path)\n",
    "\n",
    "# CV用の配列を初期化\n",
    "oof_predictions = np.zeros((len(train), len(cfg.target_cols)))\n",
    "models = {}\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(gkf.split(train, groups=train[\"scene\"])):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "\n",
    "    # データセットの作成\n",
    "    train_dataset = CustomDataset(\n",
    "        train[train_idx], cfg.data.img_root, cfg.data.json_root, cfg.data.depth_root, transform=get_train_transform()\n",
    "    )\n",
    "    valid_dataset = CustomDataset(\n",
    "        train[valid_idx], cfg.data.img_root, cfg.data.json_root, cfg.data.depth_root, transform=get_valid_transform()\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=cfg.cnn.batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=cfg.cnn.batch_size, shuffle=False)\n",
    "\n",
    "    # モデル、損失関数、オプティマイザーの初期化\n",
    "    model = CustomModel(cfg.cnn).to(device)\n",
    "    criterion = nn.HuberLoss()\n",
    "    # criterion = nn.L1Loss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.cnn.lr)\n",
    "    total_steps = len(train_loader) * cfg.cnn.num_epochs\n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=total_steps * 0.1,\n",
    "        num_training_steps=total_steps,\n",
    "    )\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "\n",
    "    # 学習ループ\n",
    "    for epoch in range(cfg.cnn.num_epochs):\n",
    "        model.train()\n",
    "        for images, targets in tqdm(train_loader):\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        # 検証\n",
    "        model.eval()\n",
    "        valid_losses = []\n",
    "        with torch.no_grad():\n",
    "            for images, targets in valid_loader:\n",
    "                images = images.to(device)\n",
    "                targets = targets.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, targets)\n",
    "                valid_losses.append(loss.item())\n",
    "\n",
    "        valid_loss = np.mean(valid_losses)\n",
    "        print(f\"Epoch {epoch + 1}, Valid Loss: {valid_loss:.4f}\")\n",
    "\n",
    "        # ベストモデルの保存\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            torch.save(model.state_dict(), f\"{cfg.data.results_path}/model_fold{fold}.pth\")\n",
    "\n",
    "    # ベストモデルでOOF予測\n",
    "    model.load_state_dict(torch.load(f\"{cfg.data.results_path}/model_fold{fold}.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    valid_dataset = CustomDataset(\n",
    "        train[valid_idx], cfg.data.img_root, cfg.data.json_root, cfg.data.depth_root, transform=get_valid_transform()\n",
    "    )\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=cfg.cnn.batch_size, shuffle=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, _) in enumerate(valid_loader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            start_idx = i * cfg.cnn.batch_size\n",
    "            end_idx = start_idx + outputs.shape[0]\n",
    "            oof_predictions[valid_idx[start_idx:end_idx]] = outputs.cpu().numpy()\n",
    "\n",
    "# CVスコアの計算（MAEの平均）\n",
    "mae_scores = []\n",
    "for i in range(len(cfg.target_cols)):\n",
    "    mae = np.mean(np.abs(oof_predictions[:, i] - train[cfg.target_cols[i]].to_numpy()))\n",
    "    mae_scores.append(mae)\n",
    "\n",
    "cv_score = np.mean(mae_scores)\n",
    "print(f\"CV Score: {cv_score:.4f}\")\n",
    "\n",
    "# oofを保存\n",
    "np.save(f\"{cfg.data.results_path}/oof_predictions.npy\", oof_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting using fold 1 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1568158/236869104.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f\"{cfg.data.results_path}/model_fold{fold}.pth\"))\n",
      "100%|██████████| 54/54 [00:13<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting using fold 2 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:09<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting using fold 3 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:10<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting using fold 4 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:10<00:00,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 18)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>x_0</th><th>y_0</th><th>z_0</th><th>x_1</th><th>y_1</th><th>z_1</th><th>x_2</th><th>y_2</th><th>z_2</th><th>x_3</th><th>y_3</th><th>z_3</th><th>x_4</th><th>y_4</th><th>z_4</th><th>x_5</th><th>y_5</th><th>z_5</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1.910416</td><td>0.015323</td><td>-0.00203</td><td>4.111138</td><td>0.049189</td><td>0.001671</td><td>6.400317</td><td>0.093142</td><td>0.001914</td><td>8.764425</td><td>0.14443</td><td>0.008326</td><td>11.181863</td><td>0.203873</td><td>0.013329</td><td>13.635955</td><td>0.27344</td><td>0.019102</td></tr><tr><td>0.888904</td><td>0.273903</td><td>-0.002772</td><td>1.869887</td><td>0.726532</td><td>0.002171</td><td>2.899538</td><td>1.31719</td><td>0.011759</td><td>3.96669</td><td>2.022292</td><td>0.024279</td><td>5.108733</td><td>2.831406</td><td>0.041865</td><td>6.321622</td><td>3.753189</td><td>0.058737</td></tr><tr><td>2.079381</td><td>0.006609</td><td>-0.00427</td><td>4.220596</td><td>0.019128</td><td>-0.009004</td><td>6.19882</td><td>0.029642</td><td>-0.013304</td><td>8.010659</td><td>0.044004</td><td>-0.018825</td><td>9.672832</td><td>0.050245</td><td>-0.025318</td><td>11.221782</td><td>0.051523</td><td>-0.033896</td></tr><tr><td>0.916636</td><td>0.02805</td><td>-0.007229</td><td>1.805815</td><td>0.074985</td><td>-0.013208</td><td>2.588893</td><td>0.138594</td><td>-0.01687</td><td>3.264247</td><td>0.217395</td><td>-0.021215</td><td>3.85386</td><td>0.317263</td><td>-0.025356</td><td>4.371171</td><td>0.43165</td><td>-0.027858</td></tr><tr><td>1.283522</td><td>-0.002682</td><td>-0.005985</td><td>2.565668</td><td>-0.007541</td><td>-0.012687</td><td>3.715343</td><td>-0.017339</td><td>-0.020631</td><td>4.736634</td><td>-0.026279</td><td>-0.029341</td><td>5.637933</td><td>-0.035247</td><td>-0.039212</td><td>6.447492</td><td>-0.048434</td><td>-0.048612</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 18)\n",
       "┌──────────┬───────────┬───────────┬──────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ x_0      ┆ y_0       ┆ z_0       ┆ x_1      ┆ … ┆ z_4       ┆ x_5       ┆ y_5       ┆ z_5       │\n",
       "│ ---      ┆ ---       ┆ ---       ┆ ---      ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ f64      ┆ f64       ┆ f64       ┆ f64      ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞══════════╪═══════════╪═══════════╪══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 1.910416 ┆ 0.015323  ┆ -0.00203  ┆ 4.111138 ┆ … ┆ 0.013329  ┆ 13.635955 ┆ 0.27344   ┆ 0.019102  │\n",
       "│ 0.888904 ┆ 0.273903  ┆ -0.002772 ┆ 1.869887 ┆ … ┆ 0.041865  ┆ 6.321622  ┆ 3.753189  ┆ 0.058737  │\n",
       "│ 2.079381 ┆ 0.006609  ┆ -0.00427  ┆ 4.220596 ┆ … ┆ -0.025318 ┆ 11.221782 ┆ 0.051523  ┆ -0.033896 │\n",
       "│ 0.916636 ┆ 0.02805   ┆ -0.007229 ┆ 1.805815 ┆ … ┆ -0.025356 ┆ 4.371171  ┆ 0.43165   ┆ -0.027858 │\n",
       "│ 1.283522 ┆ -0.002682 ┆ -0.005985 ┆ 2.565668 ┆ … ┆ -0.039212 ┆ 6.447492  ┆ -0.048434 ┆ -0.048612 │\n",
       "└──────────┴───────────┴───────────┴──────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testの推論\n",
    "test_dataset = CustomDataset(\n",
    "    test, cfg.data.img_root, cfg.data.json_root, cfg.data.depth_root, transform=get_valid_transform(), is_train=False\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=cfg.cnn.batch_size, shuffle=False)\n",
    "\n",
    "# fold分の予測値を格納する配列\n",
    "test_predictions = np.zeros((len(test), len(cfg.target_cols), cfg.n_splits))\n",
    "\n",
    "# 各foldのモデルで予測\n",
    "for fold in range(cfg.n_splits):\n",
    "    print(f\"Predicting using fold {fold + 1} model\")\n",
    "\n",
    "    # モデルの読み込み\n",
    "    model = CustomModel(cfg.cnn).to(device)\n",
    "    model.load_state_dict(torch.load(f\"{cfg.data.results_path}/model_fold{fold}.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    fold_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for images in tqdm(test_loader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            fold_predictions.append(outputs.cpu().numpy())\n",
    "\n",
    "    # バッチごとの予測を結合\n",
    "    fold_predictions = np.concatenate(fold_predictions, axis=0)\n",
    "    test_predictions[:, :, fold] = fold_predictions\n",
    "\n",
    "# fold分の予測値の平均を計算\n",
    "final_predictions = test_predictions.mean(axis=2)\n",
    "\n",
    "# submissionファイルの作成\n",
    "exprs = [pl.Series(final_predictions[:, i]).alias(cfg.target_cols[i]) for i in range(len(cfg.target_cols))]\n",
    "submission = sample_submission.with_columns(exprs)\n",
    "submission.write_csv(f\"{cfg.data.results_path}/submission.csv\")\n",
    "print(\"Submission file created!\")\n",
    "\n",
    "# 確認\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_predictionsを保存\n",
    "np.save(f\"{cfg.data.results_path}/final_predictions.npy\", final_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1727, 18)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
