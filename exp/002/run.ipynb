{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_number: '002'\n",
      "run_time: base\n",
      "data:\n",
      "  input_root: ../../data/input\n",
      "  train_path: ../../data/input/train_features.csv\n",
      "  test_path: ../../data/input/test_features.csv\n",
      "  sample_submission_path: ../../data/input/sample_submission.csv\n",
      "  img_root: ../../data/input/images\n",
      "  output_root: ../../data/output\n",
      "  results_root: ../../results\n",
      "  results_path: ../../results/002/base\n",
      "seed: 319\n",
      "n_splits: 5\n",
      "target_cols:\n",
      "- x_0\n",
      "- y_0\n",
      "- z_0\n",
      "- x_1\n",
      "- y_1\n",
      "- z_1\n",
      "- x_2\n",
      "- y_2\n",
      "- z_2\n",
      "- x_3\n",
      "- y_3\n",
      "- z_3\n",
      "- x_4\n",
      "- y_4\n",
      "- z_4\n",
      "- x_5\n",
      "- y_5\n",
      "- z_5\n",
      "cnn:\n",
      "  model_name: tf_efficientnet_b0_ns\n",
      "  size: 224\n",
      "  pretrained: true\n",
      "  in_chans: 9\n",
      "  target_size: 18\n",
      "  lr: 0.001\n",
      "  num_epochs: 20\n",
      "  batch_size: 64\n",
      "\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pytz\n",
    "import timm\n",
    "import torch\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from omegaconf import OmegaConf\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "from src.config import cfg\n",
    "from src.dir import create_dir\n",
    "from src.seed import seed_everything\n",
    "\n",
    "cfg.exp_number = Path().resolve().name\n",
    "print(OmegaConf.to_yaml(cfg, resolve=True))\n",
    "\n",
    "seed_everything(cfg.seed)\n",
    "pl.Config.set_fmt_str_lengths(1000)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exp002\n",
    "\n",
    "- NNモデルを作ってみるnotebook\n",
    "- とりあえずCNNで特徴抽出 → 全結合層で回帰というシンプルなアーキテクチャを採用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "train = pl.read_csv(cfg.data.train_path, try_parse_dates=True)\n",
    "test = pl.read_csv(cfg.data.test_path, try_parse_dates=True)\n",
    "sample_submission = pl.read_csv(cfg.data.sample_submission_path, try_parse_dates=True)\n",
    "\n",
    "# データの結合(label encoding用)\n",
    "train_test = pl.concat([train, test], how=\"diagonal\")\n",
    "\n",
    "# scene列を作成 → これでGroupKFoldする\n",
    "train = train.with_columns(pl.col(\"ID\").str.split(\"_\").list[0].alias(\"scene\"))\n",
    "test = test.with_columns(pl.col(\"ID\").str.split(\"_\").list[0].alias(\"scene\"))\n",
    "\n",
    "# CV\n",
    "gkf = GroupKFold(n_splits=cfg.n_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 31)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ID</th><th>vEgo</th><th>aEgo</th><th>steeringAngleDeg</th><th>steeringTorque</th><th>brake</th><th>brakePressed</th><th>gas</th><th>gasPressed</th><th>gearShifter</th><th>leftBlinker</th><th>rightBlinker</th><th>x_0</th><th>y_0</th><th>z_0</th><th>x_1</th><th>y_1</th><th>z_1</th><th>x_2</th><th>y_2</th><th>z_2</th><th>x_3</th><th>y_3</th><th>z_3</th><th>x_4</th><th>y_4</th><th>z_4</th><th>x_5</th><th>y_5</th><th>z_5</th><th>scene</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>bool</td><td>f64</td><td>bool</td><td>str</td><td>bool</td><td>bool</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>&quot;00066be8e20318869c38c66be466631a_320&quot;</td><td>5.701526</td><td>1.538456</td><td>-2.165777</td><td>-139.0</td><td>0.0</td><td>false</td><td>0.25</td><td>true</td><td>&quot;drive&quot;</td><td>false</td><td>false</td><td>2.82959</td><td>0.032226</td><td>0.045187</td><td>6.231999</td><td>0.065895</td><td>0.107974</td><td>9.785009</td><td>0.124972</td><td>0.203649</td><td>13.485472</td><td>0.163448</td><td>0.302818</td><td>17.574227</td><td>0.174289</td><td>0.406331</td><td>21.951269</td><td>0.199503</td><td>0.485079</td><td>&quot;00066be8e20318869c38c66be466631a&quot;</td></tr><tr><td>&quot;00066be8e20318869c38c66be466631a_420&quot;</td><td>11.176292</td><td>0.279881</td><td>-11.625697</td><td>-44.0</td><td>0.0</td><td>false</td><td>0.0</td><td>false</td><td>&quot;drive&quot;</td><td>false</td><td>true</td><td>4.970268</td><td>-0.007936</td><td>0.005028</td><td>10.350489</td><td>-0.032374</td><td>-0.020701</td><td>15.770054</td><td>0.084073</td><td>0.008645</td><td>21.132415</td><td>0.391343</td><td>0.036335</td><td>26.316489</td><td>0.843124</td><td>0.065</td><td>31.383814</td><td>1.42507</td><td>0.073083</td><td>&quot;00066be8e20318869c38c66be466631a&quot;</td></tr><tr><td>&quot;00066be8e20318869c38c66be466631a_520&quot;</td><td>10.472548</td><td>0.231099</td><td>-2.985105</td><td>-132.0</td><td>0.0</td><td>false</td><td>0.18</td><td>true</td><td>&quot;drive&quot;</td><td>false</td><td>false</td><td>4.815701</td><td>-0.000813</td><td>0.017577</td><td>10.153522</td><td>-0.0278</td><td>0.026165</td><td>15.446539</td><td>-0.155987</td><td>0.040397</td><td>20.61816</td><td>-0.356932</td><td>0.058765</td><td>25.677387</td><td>-0.576985</td><td>0.102859</td><td>30.460033</td><td>-0.841894</td><td>0.152889</td><td>&quot;00066be8e20318869c38c66be466631a&quot;</td></tr><tr><td>&quot;000fb056f97572d384bae4f5fc1e0f28_120&quot;</td><td>6.055565</td><td>-0.117775</td><td>7.632668</td><td>173.0</td><td>0.0</td><td>false</td><td>0.0</td><td>false</td><td>&quot;drive&quot;</td><td>false</td><td>false</td><td>2.812608</td><td>0.033731</td><td>0.0059</td><td>5.975378</td><td>0.137848</td><td>0.01621</td><td>9.186793</td><td>0.322997</td><td>0.031626</td><td>12.37311</td><td>0.603145</td><td>0.031858</td><td>15.703514</td><td>0.960717</td><td>0.043479</td><td>19.311182</td><td>1.374655</td><td>0.058754</td><td>&quot;000fb056f97572d384bae4f5fc1e0f28&quot;</td></tr><tr><td>&quot;000fb056f97572d384bae4f5fc1e0f28_20&quot;</td><td>3.316744</td><td>1.276733</td><td>-31.725477</td><td>-114.0</td><td>0.0</td><td>false</td><td>0.255</td><td>true</td><td>&quot;drive&quot;</td><td>false</td><td>false</td><td>1.55186</td><td>-0.041849</td><td>-0.008847</td><td>3.675162</td><td>-0.125189</td><td>-0.013725</td><td>6.113567</td><td>-0.239161</td><td>-0.012887</td><td>8.770783</td><td>-0.381813</td><td>-0.003898</td><td>11.619313</td><td>-0.554488</td><td>0.011393</td><td>14.657048</td><td>-0.7788</td><td>0.044243</td><td>&quot;000fb056f97572d384bae4f5fc1e0f28&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 31)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬──────────┬───────────┐\n",
       "│ ID        ┆ vEgo      ┆ aEgo      ┆ steeringA ┆ … ┆ x_5       ┆ y_5       ┆ z_5      ┆ scene     │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ngleDeg   ┆   ┆ ---       ┆ ---       ┆ ---      ┆ ---       │\n",
       "│ str       ┆ f64       ┆ f64       ┆ ---       ┆   ┆ f64       ┆ f64       ┆ f64      ┆ str       │\n",
       "│           ┆           ┆           ┆ f64       ┆   ┆           ┆           ┆          ┆           │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪══════════╪═══════════╡\n",
       "│ 00066be8e ┆ 5.701526  ┆ 1.538456  ┆ -2.165777 ┆ … ┆ 21.951269 ┆ 0.199503  ┆ 0.485079 ┆ 00066be8e │\n",
       "│ 20318869c ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆ 20318869c │\n",
       "│ 38c66be46 ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆ 38c66be46 │\n",
       "│ 6631a_320 ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆ 6631a     │\n",
       "│ 00066be8e ┆ 11.176292 ┆ 0.279881  ┆ -11.62569 ┆ … ┆ 31.383814 ┆ 1.42507   ┆ 0.073083 ┆ 00066be8e │\n",
       "│ 20318869c ┆           ┆           ┆ 7         ┆   ┆           ┆           ┆          ┆ 20318869c │\n",
       "│ 38c66be46 ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆ 38c66be46 │\n",
       "│ 6631a_420 ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆ 6631a     │\n",
       "│ 00066be8e ┆ 10.472548 ┆ 0.231099  ┆ -2.985105 ┆ … ┆ 30.460033 ┆ -0.841894 ┆ 0.152889 ┆ 00066be8e │\n",
       "│ 20318869c ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆ 20318869c │\n",
       "│ 38c66be46 ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆ 38c66be46 │\n",
       "│ 6631a_520 ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆ 6631a     │\n",
       "│ 000fb056f ┆ 6.055565  ┆ -0.117775 ┆ 7.632668  ┆ … ┆ 19.311182 ┆ 1.374655  ┆ 0.058754 ┆ 000fb056f │\n",
       "│ 97572d384 ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆ 97572d384 │\n",
       "│ bae4f5fc1 ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆ bae4f5fc1 │\n",
       "│ e0f28_120 ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆ e0f28     │\n",
       "│ 000fb056f ┆ 3.316744  ┆ 1.276733  ┆ -31.72547 ┆ … ┆ 14.657048 ┆ -0.7788   ┆ 0.044243 ┆ 000fb056f │\n",
       "│ 97572d384 ┆           ┆           ┆ 7         ┆   ┆           ┆           ┆          ┆ 97572d384 │\n",
       "│ bae4f5fc1 ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆ bae4f5fc1 │\n",
       "│ e0f28_20  ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆ e0f28     │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴──────────┴───────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ拡張\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(cfg.cnn.size, cfg.cnn.size),\n",
    "            A.OneOf(\n",
    "                [\n",
    "                    A.GaussNoise(var_limit=[10, 50]),\n",
    "                    A.GaussianBlur(),\n",
    "                    A.MotionBlur(),\n",
    "                ],\n",
    "                p=0.4,\n",
    "            ),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_valid_transform():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(cfg.cnn.size, cfg.cnn.size),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None, is_train=True):\n",
    "        self.df = df\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.is_train = is_train\n",
    "\n",
    "        # デフォルトの変換処理\n",
    "        if transform is None:\n",
    "            self.transform = A.Compose(\n",
    "                [\n",
    "                    A.Resize(cfg.cnn.size, cfg.cnn.size),\n",
    "                    A.Normalize(\n",
    "                        mean=[0.485, 0.456, 0.406],  # 通常のImageNet平均値\n",
    "                        std=[0.229, 0.224, 0.225],  # 通常のImageNet標準偏差\n",
    "                    ),\n",
    "                    ToTensorV2(),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            self.transform = transform\n",
    "\n",
    "        self.target_cols = cfg.target_cols\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df[idx]\n",
    "        img_folder = self.img_dir / row[\"ID\"].item()\n",
    "\n",
    "        # 3枚の画像を読み込み、変換を適用\n",
    "        img_names = [\"image_t-1.0.png\", \"image_t-0.5.png\", \"image_t.png\"]\n",
    "        transformed_imgs = []\n",
    "\n",
    "        for img_name in img_names:\n",
    "            img_path = img_folder / img_name\n",
    "            img = cv2.imread(str(img_path))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            if self.transform:\n",
    "                transformed = self.transform(image=img)\n",
    "                transformed_imgs.append(transformed[\"image\"])\n",
    "\n",
    "        # チャネル方向に結合 (C*3, H, W)\n",
    "        img_tensor = torch.cat(transformed_imgs, dim=0)\n",
    "\n",
    "        # ターゲットの準備\n",
    "        if self.is_train:\n",
    "            target = torch.tensor(row[self.target_cols].to_numpy(), dtype=torch.float32).squeeze(0)\n",
    "            return img_tensor, target\n",
    "        else:\n",
    "            return img_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, pretrained=False, target_size=None, model_name=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = timm.create_model(\n",
    "            cfg.model_name, pretrained=cfg.pretrained, num_classes=0, in_chans=cfg.in_chans\n",
    "        )\n",
    "\n",
    "        self.n_features = self.encoder.num_features\n",
    "\n",
    "        self.target_size = cfg.target_size if target_size is None else target_size\n",
    "\n",
    "        # nn.Dropout(0.5),\n",
    "        self.fc = nn.Sequential(nn.Linear(self.n_features, self.target_size))\n",
    "\n",
    "    def get_embedding(self, image):\n",
    "        with torch.no_grad():\n",
    "            feature = self.encoder(image)\n",
    "        return feature\n",
    "\n",
    "    def forward(self, image):\n",
    "        feature = self.encoder(image)\n",
    "        output = self.fc(feature)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marumarukun/pj/compe/atma_18/.venv/lib/python3.12/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
      "  model = create_fn(\n"
     ]
    }
   ],
   "source": [
    "model = CustomModel(cfg.cnn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "if DEBUG:\n",
    "    cfg.cnn.num_epochs = 1\n",
    "    train = train.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory created: ../../results/002/20241119_220952\n",
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marumarukun/pj/compe/atma_18/.venv/lib/python3.12/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
      "  model = create_fn(\n",
      "100%|██████████| 543/543 [04:07<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Valid Loss: 0.9335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:42<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Valid Loss: 1.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:42<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Valid Loss: 0.7310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:41<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Valid Loss: 0.7233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:42<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Valid Loss: 0.8505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:41<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Valid Loss: 0.6786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:43<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Valid Loss: 0.6326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:44<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Valid Loss: 0.6184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Valid Loss: 0.6228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:46<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Valid Loss: 0.5927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:53<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Valid Loss: 0.5634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:44<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Valid Loss: 0.5613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:44<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Valid Loss: 0.5627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:39<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Valid Loss: 0.5551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Valid Loss: 0.5464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:39<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Valid Loss: 0.5414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:37<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Valid Loss: 0.5378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:36<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Valid Loss: 0.5386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:36<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Valid Loss: 0.5372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:37<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Valid Loss: 0.5370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182840/1479182690.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f\"{cfg.data.results_path}/model_fold{fold}.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:39<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Valid Loss: 0.9964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Valid Loss: 0.8410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:37<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Valid Loss: 0.8140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:38<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Valid Loss: 0.7425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:38<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Valid Loss: 0.9016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Valid Loss: 0.6894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:41<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Valid Loss: 0.6780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Valid Loss: 0.6301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Valid Loss: 0.6096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:41<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Valid Loss: 0.5877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Valid Loss: 0.5868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Valid Loss: 0.5659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:37<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Valid Loss: 0.5656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:41<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Valid Loss: 0.5594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:41<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Valid Loss: 0.5525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:41<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Valid Loss: 0.5539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:42<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Valid Loss: 0.5522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:41<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Valid Loss: 0.5504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Valid Loss: 0.5513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:41<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Valid Loss: 0.5490\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:41<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Valid Loss: 0.8847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:42<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Valid Loss: 0.9658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:39<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Valid Loss: 0.7464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:41<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Valid Loss: 0.7115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:41<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Valid Loss: 0.6969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:42<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Valid Loss: 0.7258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:41<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Valid Loss: 0.6694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Valid Loss: 0.6075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Valid Loss: 0.6188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Valid Loss: 0.6349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:42<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Valid Loss: 0.5814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Valid Loss: 0.5821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:43<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Valid Loss: 0.5526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:41<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Valid Loss: 0.5521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:41<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Valid Loss: 0.5476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Valid Loss: 0.5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:41<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Valid Loss: 0.5468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:39<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Valid Loss: 0.5438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:41<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Valid Loss: 0.5433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Valid Loss: 0.5422\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:38<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Valid Loss: 1.0557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:38<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Valid Loss: 0.7965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:39<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Valid Loss: 0.7717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:39<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Valid Loss: 0.7169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:38<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Valid Loss: 0.7616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Valid Loss: 0.6428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:39<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Valid Loss: 0.6410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Valid Loss: 0.8363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:39<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Valid Loss: 0.6354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:39<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Valid Loss: 0.5758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:39<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Valid Loss: 0.5855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:38<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Valid Loss: 0.5695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:39<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Valid Loss: 0.5663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Valid Loss: 0.5532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:42<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Valid Loss: 0.5526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Valid Loss: 0.5470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Valid Loss: 0.5465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Valid Loss: 0.5453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:39<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Valid Loss: 0.5470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:39<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Valid Loss: 0.5464\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:37<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Valid Loss: 1.0397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:34<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Valid Loss: 0.9606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:35<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Valid Loss: 0.7289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:35<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Valid Loss: 0.7697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:39<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Valid Loss: 0.6824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:39<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Valid Loss: 0.6806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Valid Loss: 0.6827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Valid Loss: 0.6352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Valid Loss: 0.6104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:41<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Valid Loss: 0.6043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Valid Loss: 0.5900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:39<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Valid Loss: 0.5768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Valid Loss: 0.5753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Valid Loss: 0.5668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:41<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Valid Loss: 0.5760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:41<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Valid Loss: 0.5699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:41<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Valid Loss: 0.5648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:41<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Valid Loss: 0.5587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:41<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Valid Loss: 0.5583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 543/543 [03:40<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Valid Loss: 0.5590\n",
      "CV Score: 0.7547\n"
     ]
    }
   ],
   "source": [
    "# 実験結果格納用のディレクトリを作成\n",
    "japan_tz = pytz.timezone(\"Asia/Tokyo\")\n",
    "cfg.run_time = datetime.now(japan_tz).strftime(\"%Y%m%d_%H%M%S\")\n",
    "create_dir(cfg.data.results_path)\n",
    "\n",
    "# CV用の配列を初期化\n",
    "oof_predictions = np.zeros((len(train), len(cfg.target_cols)))\n",
    "models = {}\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(gkf.split(train, groups=train[\"scene\"])):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "\n",
    "    # データセットの作成\n",
    "    train_dataset = CustomDataset(train[train_idx], cfg.data.img_root, transform=get_train_transform())\n",
    "    valid_dataset = CustomDataset(train[valid_idx], cfg.data.img_root, transform=get_valid_transform())\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=cfg.cnn.batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=cfg.cnn.batch_size, shuffle=False)\n",
    "\n",
    "    # モデル、損失関数、オプティマイザーの初期化\n",
    "    model = CustomModel(cfg.cnn).to(device)\n",
    "    criterion = nn.HuberLoss()\n",
    "    # criterion = nn.L1Loss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.cnn.lr)\n",
    "    total_steps = len(train_loader) * cfg.cnn.num_epochs\n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=total_steps * 0.1,\n",
    "        num_training_steps=total_steps,\n",
    "    )\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "\n",
    "    # 学習ループ\n",
    "    for epoch in range(cfg.cnn.num_epochs):\n",
    "        model.train()\n",
    "        for images, targets in tqdm(train_loader):\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        # 検証\n",
    "        model.eval()\n",
    "        valid_losses = []\n",
    "        with torch.no_grad():\n",
    "            for images, targets in valid_loader:\n",
    "                images = images.to(device)\n",
    "                targets = targets.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, targets)\n",
    "                valid_losses.append(loss.item())\n",
    "\n",
    "        valid_loss = np.mean(valid_losses)\n",
    "        print(f\"Epoch {epoch + 1}, Valid Loss: {valid_loss:.4f}\")\n",
    "\n",
    "        # ベストモデルの保存\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            torch.save(model.state_dict(), f\"{cfg.data.results_path}/model_fold{fold}.pth\")\n",
    "\n",
    "    # ベストモデルでOOF予測\n",
    "    model.load_state_dict(torch.load(f\"{cfg.data.results_path}/model_fold{fold}.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    valid_dataset = CustomDataset(train[valid_idx], cfg.data.img_root, transform=get_valid_transform())\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=cfg.cnn.batch_size, shuffle=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, _) in enumerate(valid_loader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            start_idx = i * cfg.cnn.batch_size\n",
    "            end_idx = start_idx + outputs.shape[0]\n",
    "            oof_predictions[valid_idx[start_idx:end_idx]] = outputs.cpu().numpy()\n",
    "\n",
    "# CVスコアの計算（MAEの平均）\n",
    "mae_scores = []\n",
    "for i in range(len(cfg.target_cols)):\n",
    "    mae = np.mean(np.abs(oof_predictions[:, i] - train[cfg.target_cols[i]].to_numpy()))\n",
    "    mae_scores.append(mae)\n",
    "\n",
    "cv_score = np.mean(mae_scores)\n",
    "print(f\"CV Score: {cv_score:.4f}\")\n",
    "\n",
    "# oofを保存\n",
    "np.save(f\"{cfg.data.results_path}/oof_predictions.npy\", oof_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting using fold 1 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_182840/2027353737.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f\"{cfg.data.results_path}/model_fold{fold}.pth\"))\n",
      "100%|██████████| 27/27 [00:09<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting using fold 2 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:06<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting using fold 3 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:06<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting using fold 4 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:06<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting using fold 5 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:06<00:00,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 18)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>x_0</th><th>y_0</th><th>z_0</th><th>x_1</th><th>y_1</th><th>z_1</th><th>x_2</th><th>y_2</th><th>z_2</th><th>x_3</th><th>y_3</th><th>z_3</th><th>x_4</th><th>y_4</th><th>z_4</th><th>x_5</th><th>y_5</th><th>z_5</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1.564748</td><td>0.030296</td><td>-0.005134</td><td>3.22256</td><td>0.098319</td><td>-0.012699</td><td>4.787374</td><td>0.208132</td><td>-0.018557</td><td>6.273776</td><td>0.353713</td><td>-0.025955</td><td>7.681679</td><td>0.528883</td><td>-0.033389</td><td>9.024183</td><td>0.721998</td><td>-0.041702</td></tr><tr><td>1.138851</td><td>0.34751</td><td>-0.00604</td><td>2.388481</td><td>1.015732</td><td>0.000645</td><td>3.603331</td><td>1.932546</td><td>0.007776</td><td>4.801756</td><td>3.061652</td><td>0.01193</td><td>6.028886</td><td>4.369015</td><td>0.024479</td><td>7.260505</td><td>5.83338</td><td>0.036508</td></tr><tr><td>2.064555</td><td>0.008399</td><td>-0.005522</td><td>4.242183</td><td>0.022166</td><td>-0.012603</td><td>6.30258</td><td>0.045728</td><td>-0.021937</td><td>8.255037</td><td>0.076212</td><td>-0.035858</td><td>10.09707</td><td>0.110275</td><td>-0.048623</td><td>11.855469</td><td>0.142373</td><td>-0.060925</td></tr><tr><td>0.697062</td><td>-0.004701</td><td>-0.004122</td><td>1.429205</td><td>-0.012335</td><td>-0.004754</td><td>2.132749</td><td>-0.014095</td><td>-0.007812</td><td>2.808174</td><td>-0.019438</td><td>-0.009792</td><td>3.475157</td><td>-0.02116</td><td>-0.011917</td><td>4.123117</td><td>-0.030823</td><td>-0.011751</td></tr><tr><td>0.988816</td><td>0.001616</td><td>-0.007507</td><td>2.001525</td><td>0.009161</td><td>-0.016364</td><td>2.940998</td><td>0.027944</td><td>-0.028809</td><td>3.820994</td><td>0.053867</td><td>-0.040315</td><td>4.648424</td><td>0.086246</td><td>-0.052734</td><td>5.431638</td><td>0.117115</td><td>-0.067859</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 18)\n",
       "┌──────────┬───────────┬───────────┬──────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ x_0      ┆ y_0       ┆ z_0       ┆ x_1      ┆ … ┆ z_4       ┆ x_5       ┆ y_5       ┆ z_5       │\n",
       "│ ---      ┆ ---       ┆ ---       ┆ ---      ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ f64      ┆ f64       ┆ f64       ┆ f64      ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞══════════╪═══════════╪═══════════╪══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 1.564748 ┆ 0.030296  ┆ -0.005134 ┆ 3.22256  ┆ … ┆ -0.033389 ┆ 9.024183  ┆ 0.721998  ┆ -0.041702 │\n",
       "│ 1.138851 ┆ 0.34751   ┆ -0.00604  ┆ 2.388481 ┆ … ┆ 0.024479  ┆ 7.260505  ┆ 5.83338   ┆ 0.036508  │\n",
       "│ 2.064555 ┆ 0.008399  ┆ -0.005522 ┆ 4.242183 ┆ … ┆ -0.048623 ┆ 11.855469 ┆ 0.142373  ┆ -0.060925 │\n",
       "│ 0.697062 ┆ -0.004701 ┆ -0.004122 ┆ 1.429205 ┆ … ┆ -0.011917 ┆ 4.123117  ┆ -0.030823 ┆ -0.011751 │\n",
       "│ 0.988816 ┆ 0.001616  ┆ -0.007507 ┆ 2.001525 ┆ … ┆ -0.052734 ┆ 5.431638  ┆ 0.117115  ┆ -0.067859 │\n",
       "└──────────┴───────────┴───────────┴──────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testの推論\n",
    "test_dataset = CustomDataset(test, cfg.data.img_root, transform=get_valid_transform(), is_train=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=cfg.cnn.batch_size, shuffle=False)\n",
    "\n",
    "# 5fold分の予測値を格納する配列\n",
    "test_predictions = np.zeros((len(test), len(cfg.target_cols), cfg.n_splits))\n",
    "\n",
    "# 各foldのモデルで予測\n",
    "for fold in range(cfg.n_splits):\n",
    "    print(f\"Predicting using fold {fold + 1} model\")\n",
    "\n",
    "    # モデルの読み込み\n",
    "    model = CustomModel(cfg.cnn).to(device)\n",
    "    model.load_state_dict(torch.load(f\"{cfg.data.results_path}/model_fold{fold}.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    fold_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for images in tqdm(test_loader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            fold_predictions.append(outputs.cpu().numpy())\n",
    "\n",
    "    # バッチごとの予測を結合\n",
    "    fold_predictions = np.concatenate(fold_predictions, axis=0)\n",
    "    test_predictions[:, :, fold] = fold_predictions\n",
    "\n",
    "# 5fold分の予測値の平均を計算\n",
    "final_predictions = test_predictions.mean(axis=2)\n",
    "\n",
    "# submissionファイルの作成\n",
    "exprs = [pl.Series(final_predictions[:, i]).alias(cfg.target_cols[i]) for i in range(len(cfg.target_cols))]\n",
    "submission = sample_submission.with_columns(exprs)\n",
    "submission.write_csv(f\"{cfg.data.results_path}/submission.csv\")\n",
    "print(\"Submission file created!\")\n",
    "\n",
    "# 確認\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_predictionsを保存\n",
    "np.save(f\"{cfg.data.results_path}/final_predictions.npy\", final_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1727, 18)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embedding取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marumarukun/pj/compe/atma_18/.venv/lib/python3.12/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
      "  model = create_fn(\n",
      "/tmp/ipykernel_973658/20170425.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f\"{cfg.data.results_path}/model_fold{fold}.pth\"))\n",
      "100%|██████████| 136/136 [00:33<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:38<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:38<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:38<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:38<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_embeddings.shape: (43371, 1280)\n"
     ]
    }
   ],
   "source": [
    "# trainのembedding取得\n",
    "\n",
    "# model読み込み用のディレクトリを指定\n",
    "cfg.run_time = \"20241119_220952\"\n",
    "\n",
    "# train_embeddingsを格納する配列を初期化\n",
    "train_embeddings = np.zeros((len(train), model.n_features))\n",
    "\n",
    "for fold, (_, valid_idx) in enumerate(gkf.split(train, groups=train[\"scene\"])):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    model = CustomModel(cfg.cnn).to(device)\n",
    "\n",
    "    # ベストモデルでembedding取得\n",
    "    model.load_state_dict(torch.load(f\"{cfg.data.results_path}/model_fold{fold}.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    valid_dataset = CustomDataset(train[valid_idx], cfg.data.img_root, transform=get_valid_transform(), is_train=False)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=cfg.cnn.batch_size, shuffle=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, images in enumerate(tqdm(valid_loader)):\n",
    "            images = images.to(device)\n",
    "            start_idx = i * cfg.cnn.batch_size\n",
    "            end_idx = start_idx + images.shape[0]\n",
    "            train_embeddings[valid_idx[start_idx:end_idx]] = model.get_embedding(images).cpu().numpy()\n",
    "\n",
    "print(f\"train_embeddings.shape: {train_embeddings.shape}\")\n",
    "\n",
    "# train_embeddingsを保存\n",
    "np.save(f\"{cfg.data.results_path}/train_embeddings.npy\", train_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding using fold 1 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marumarukun/pj/compe/atma_18/.venv/lib/python3.12/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
      "  model = create_fn(\n",
      "/tmp/ipykernel_973658/1345804168.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f\"{cfg.data.results_path}/model_fold{fold}.pth\"))\n",
      "100%|██████████| 27/27 [00:06<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding using fold 2 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:06<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding using fold 3 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:06<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding using fold 4 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:06<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding using fold 5 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:06<00:00,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_embeddings.shape: (1727, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# testのembedding取得\n",
    "\n",
    "# testの推論\n",
    "test_dataset = CustomDataset(test, cfg.data.img_root, transform=get_valid_transform(), is_train=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=cfg.cnn.batch_size, shuffle=False)\n",
    "\n",
    "# 5fold分のembeddingを格納する配列\n",
    "test_embeddings = np.zeros((len(test), model.n_features, cfg.n_splits))\n",
    "\n",
    "# 各foldのモデルでembedding取得\n",
    "for fold in range(cfg.n_splits):\n",
    "    print(f\"Embedding using fold {fold + 1} model\")\n",
    "\n",
    "    # モデルの読み込み\n",
    "    model = CustomModel(cfg.cnn).to(device)\n",
    "    model.load_state_dict(torch.load(f\"{cfg.data.results_path}/model_fold{fold}.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    fold_embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for images in tqdm(test_loader):\n",
    "            images = images.to(device)\n",
    "            fold_embeddings.append(model.get_embedding(images).cpu().numpy())\n",
    "\n",
    "    # バッチごとのembeddingを結合\n",
    "    fold_embeddings = np.concatenate(fold_embeddings, axis=0)\n",
    "    test_embeddings[:, :, fold] = fold_embeddings\n",
    "\n",
    "# 5fold分のembeddingの平均を計算\n",
    "final_embeddings = test_embeddings.mean(axis=2)\n",
    "\n",
    "print(f\"final_embeddings.shape: {final_embeddings.shape}\")\n",
    "\n",
    "# final_embeddingsを保存\n",
    "np.save(f\"{cfg.data.results_path}/final_embeddings.npy\", final_embeddings)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
