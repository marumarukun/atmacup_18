{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import pprint\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import japanize_matplotlib\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import pytz\n",
    "import seaborn as sns\n",
    "from omegaconf import OmegaConf\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.config import cfg\n",
    "from src.dir import create_dir\n",
    "from src.seed import seed_everything\n",
    "\n",
    "cfg.exp_number = Path().resolve().name\n",
    "print(OmegaConf.to_yaml(cfg, resolve=True))\n",
    "\n",
    "seed_everything(cfg.seed)\n",
    "pl.Config.set_fmt_str_lengths(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "if DEBUG:\n",
    "    cfg.lgb.num_boost_round = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "train = pl.read_csv(cfg.data.train_path, try_parse_dates=True)\n",
    "test = pl.read_csv(cfg.data.test_path, try_parse_dates=True)\n",
    "sample_submission = pl.read_csv(cfg.data.sample_submission_path, try_parse_dates=True)\n",
    "\n",
    "# 前処理\n",
    "\n",
    "# indexを作成（学習、推論前に元の順序情報を復元するため）\n",
    "train = train.with_row_index()\n",
    "test = test.with_row_index()\n",
    "\n",
    "# bool型をint8に変換\n",
    "train = train.with_columns(train.select(pl.col(pl.Boolean).cast(pl.Int8)))\n",
    "test = test.with_columns(test.select(pl.col(pl.Boolean).cast(pl.Int8)))\n",
    "\n",
    "# scene列を作成 → これでGroupKFoldする\n",
    "train = train.with_columns(pl.col(\"ID\").str.split(\"_\").list[0].alias(\"scene\"))\n",
    "test = test.with_columns(pl.col(\"ID\").str.split(\"_\").list[0].alias(\"scene\"))\n",
    "\n",
    "# decisecond列を作成\n",
    "train = train.with_columns(pl.col(\"ID\").str.split(\"_\").list[1].cast(pl.Int32).alias(\"decisecond\"))\n",
    "test = test.with_columns(pl.col(\"ID\").str.split(\"_\").list[1].cast(pl.Int32).alias(\"decisecond\"))\n",
    "\n",
    "# trainとtestを結合する（ラベルエンコーディング用）\n",
    "train_test = pl.concat([train, test], how=\"diagonal\")\n",
    "\n",
    "# CV\n",
    "gkf = GroupKFold(n_splits=cfg.n_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_features(img_dir, depth_dir):\n",
    "    features = {}\n",
    "    sec_list = [\"t-1.0\", \"t-0.5\", \"t\"]\n",
    "\n",
    "    # 3枚の画像を読み込みとDepth画像を読み込み\n",
    "    images = []\n",
    "    depths = []\n",
    "    for sec in sec_list:\n",
    "        img_path = Path(img_dir) / f\"image_{sec}.png\"\n",
    "        depth_path = Path(depth_dir) / f\"image_{sec}.png\"\n",
    "        img = cv2.imread(str(img_path))\n",
    "        depth = cv2.imread(str(depth_path))\n",
    "        images.append(img)\n",
    "        depths.append(depth)\n",
    "\n",
    "    # RGB画像とDepth画像の両方に対して特徴抽出\n",
    "    for sec, img, depth in zip(sec_list, images, depths, strict=True):\n",
    "        # RGB画像の基本統計量\n",
    "        features[f\"variance_{sec}\"] = np.var(img)\n",
    "        features[f\"mean_brightness_{sec}\"] = np.mean(img)\n",
    "\n",
    "        # Depth画像の基本統計量\n",
    "        features[f\"variance_depth_{sec}\"] = np.var(depth)\n",
    "        features[f\"mean_depth_{sec}\"] = np.mean(depth)\n",
    "\n",
    "        # RGB画像のエッジ特徴\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        edges = cv2.Canny(gray, 100, 200)\n",
    "        features[f\"edge_density_{sec}\"] = np.mean(edges > 0)\n",
    "\n",
    "        # Depth画像のエッジ特徴\n",
    "        depth_gray = cv2.cvtColor(depth, cv2.COLOR_BGR2GRAY)\n",
    "        depth_edges = cv2.Canny(depth_gray, 100, 200)\n",
    "        features[f\"depth_edge_density_{sec}\"] = np.mean(depth_edges > 0)\n",
    "\n",
    "        # RGB画像の色相ヒストグラム\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        hist = cv2.calcHist([hsv], [0], None, [6], [0, 180])\n",
    "        for bin_idx in range(6):\n",
    "            features[f\"hue_bin_{sec}_{bin_idx}\"] = hist[bin_idx][0]\n",
    "\n",
    "        # RGB画像の上部/下部での特徴の違い\n",
    "        height = img.shape[0]\n",
    "        upper_half = img[: height // 2, :, :]\n",
    "        lower_half = img[height // 2 :, :, :]\n",
    "        features[f\"upper_brightness_{sec}\"] = np.mean(upper_half)\n",
    "        features[f\"lower_brightness_{sec}\"] = np.mean(lower_half)\n",
    "        features[f\"brightness_ratio_{sec}\"] = features[f\"upper_brightness_{sec}\"] / (\n",
    "            features[f\"lower_brightness_{sec}\"] + 1e-6\n",
    "        )\n",
    "\n",
    "        # Depth画像の上部/下部での特徴の違い\n",
    "        depth_upper = depth[: height // 2, :, :]\n",
    "        depth_lower = depth[height // 2 :, :, :]\n",
    "        features[f\"depth_upper_mean_{sec}\"] = np.mean(depth_upper)\n",
    "        features[f\"depth_lower_mean_{sec}\"] = np.mean(depth_lower)\n",
    "        features[f\"depth_vertical_ratio_{sec}\"] = features[f\"depth_upper_mean_{sec}\"] / (\n",
    "            features[f\"depth_lower_mean_{sec}\"] + 1e-6\n",
    "        )\n",
    "\n",
    "        # RGB画像の左右での特徴の違い\n",
    "        width = img.shape[1]\n",
    "        left_half = img[:, : width // 2, :]\n",
    "        right_half = img[:, width // 2 :, :]\n",
    "        features[f\"left_brightness_{sec}\"] = np.mean(left_half)\n",
    "        features[f\"right_brightness_{sec}\"] = np.mean(right_half)\n",
    "        features[f\"lr_brightness_ratio_{sec}\"] = features[f\"left_brightness_{sec}\"] / (\n",
    "            features[f\"right_brightness_{sec}\"] + 1e-6\n",
    "        )\n",
    "\n",
    "        # Depth画像の左右での特徴の違い\n",
    "        depth_left = depth[:, : width // 2, :]\n",
    "        depth_right = depth[:, width // 2 :, :]\n",
    "        features[f\"depth_left_mean_{sec}\"] = np.mean(depth_left)\n",
    "        features[f\"depth_right_mean_{sec}\"] = np.mean(depth_right)\n",
    "        features[f\"depth_horizontal_ratio_{sec}\"] = features[f\"depth_left_mean_{sec}\"] / (\n",
    "            features[f\"depth_right_mean_{sec}\"] + 1e-6\n",
    "        )\n",
    "\n",
    "        # RGB画像のテクスチャ特徴\n",
    "        features[f\"texture_contrast_{sec}\"] = np.std(gray)\n",
    "\n",
    "        # Depth画像のテクスチャ特徴\n",
    "        features[f\"depth_texture_contrast_{sec}\"] = np.std(depth_gray)\n",
    "\n",
    "        # RGB画像のエッジの方向性\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        features[f\"edge_direction_{sec}\"] = np.mean(np.arctan2(sobely, sobelx))\n",
    "\n",
    "        # Depth画像のエッジの方向性と勾配強度\n",
    "        depth_sobelx = cv2.Sobel(depth_gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        depth_sobely = cv2.Sobel(depth_gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        features[f\"depth_gradient_direction_{sec}\"] = np.mean(np.arctan2(depth_sobely, depth_sobelx))\n",
    "        features[f\"depth_gradient_magnitude_{sec}\"] = np.mean(np.sqrt(depth_sobelx**2 + depth_sobely**2))\n",
    "\n",
    "        # Depth画像の四分位数特徴\n",
    "        depth_quartiles = np.percentile(depth_gray, [25, 50, 75])\n",
    "        features[f\"depth_q1_{sec}\"] = depth_quartiles[0]\n",
    "        features[f\"depth_q2_{sec}\"] = depth_quartiles[1]\n",
    "        features[f\"depth_q3_{sec}\"] = depth_quartiles[2]\n",
    "        features[f\"depth_iqr_{sec}\"] = depth_quartiles[2] - depth_quartiles[0]\n",
    "\n",
    "    # 画像間の差分特徴（RGB画像とDepth画像の両方）\n",
    "    for i in range(2):\n",
    "        # RGB画像の差分\n",
    "        rgb_diff = cv2.absdiff(images[i], images[i + 1])\n",
    "        features[f\"frame_diff_{sec_list[i]}_{sec_list[i + 1]}\"] = np.mean(rgb_diff)\n",
    "\n",
    "        # Depth画像の差分\n",
    "        depth_diff = cv2.absdiff(depths[i], depths[i + 1])\n",
    "        features[f\"depth_diff_{sec_list[i]}_{sec_list[i + 1]}\"] = np.mean(depth_diff)\n",
    "\n",
    "        # Depth画像の差分の統計量\n",
    "        features[f\"depth_diff_std_{sec_list[i]}_{sec_list[i + 1]}\"] = np.std(depth_diff)\n",
    "        features[f\"depth_diff_max_{sec_list[i]}_{sec_list[i + 1]}\"] = np.max(depth_diff)\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像特徴量のdfへの結合\n",
    "def add_image_features(df):\n",
    "    all_features = []\n",
    "    for id_name in tqdm(df[\"ID\"]):\n",
    "        img_dir = Path(cfg.data.img_root) / id_name\n",
    "        depth_dir = Path(cfg.data.depth_root) / id_name\n",
    "\n",
    "        features = extract_image_features(img_dir, depth_dir)\n",
    "        features[\"ID\"] = id_name\n",
    "        all_features.append(features)\n",
    "\n",
    "    # 画像特徴量のdfを作成\n",
    "    img_features_df = pl.DataFrame(all_features)\n",
    "\n",
    "    # 元のdfと結合\n",
    "    return df.join(img_features_df, how=\"left\", on=\"ID\")\n",
    "\n",
    "\n",
    "# trainに画像特徴量を追加\n",
    "train = add_image_features(train)\n",
    "\n",
    "# testに画像特徴量を追加\n",
    "test = add_image_features(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp011のoofとpredictionsを特徴量として追加(train, testのデータの順序が変わっていないか注意)\n",
    "oof_exp011 = np.load(\"../../results/011/20241125_171020/oof_predictions.npy\")\n",
    "predictions_exp011 = np.load(\"../../results/011/20241125_171020/final_predictions.npy\")\n",
    "\n",
    "# trainにoofを追加\n",
    "exprs = []\n",
    "exprs += [pl.Series(oof_exp011[:, i]).alias(f\"exp011_nn_{cfg.target_cols[i]}\") for i in range(len(cfg.target_cols))]\n",
    "train = train.with_columns(exprs)\n",
    "\n",
    "# testにpredictionsを追加\n",
    "exprs = []\n",
    "exprs += [\n",
    "    pl.Series(predictions_exp011[:, i]).alias(f\"exp011_nn_{cfg.target_cols[i]}\") for i in range(len(cfg.target_cols))\n",
    "]\n",
    "test = test.with_columns(exprs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 物理量の組合せ特徴量\n",
    "\n",
    "# 速度と加速度の組み合わせ\n",
    "train = train.with_columns(\n",
    "    [\n",
    "        (pl.col(\"vEgo\") * pl.col(\"aEgo\")).alias(\"velocity_acceleration\"),\n",
    "        (pl.col(\"vEgo\") * pl.col(\"steeringAngleDeg\")).alias(\"velocity_steering\"),\n",
    "        (pl.col(\"aEgo\") * pl.col(\"steeringAngleDeg\")).alias(\"acceleration_steering\"),\n",
    "    ]\n",
    ")\n",
    "test = test.with_columns(\n",
    "    [\n",
    "        (pl.col(\"vEgo\") * pl.col(\"aEgo\")).alias(\"velocity_acceleration\"),\n",
    "        (pl.col(\"vEgo\") * pl.col(\"steeringAngleDeg\")).alias(\"velocity_steering\"),\n",
    "        (pl.col(\"aEgo\") * pl.col(\"steeringAngleDeg\")).alias(\"acceleration_steering\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 二乗項（非線形性の捕捉）\n",
    "train = train.with_columns(\n",
    "    [\n",
    "        (pl.col(\"vEgo\") ** 2).alias(\"vEgo_squared\"),\n",
    "        (pl.col(\"aEgo\") ** 2).alias(\"aEgo_squared\"),\n",
    "        (pl.col(\"steeringAngleDeg\") ** 2).alias(\"steering_squared\"),\n",
    "    ]\n",
    ")\n",
    "test = test.with_columns(\n",
    "    [\n",
    "        (pl.col(\"vEgo\") ** 2).alias(\"vEgo_squared\"),\n",
    "        (pl.col(\"aEgo\") ** 2).alias(\"aEgo_squared\"),\n",
    "        (pl.col(\"steeringAngleDeg\") ** 2).alias(\"steering_squared\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gearShifterのラベルエンコーディング\n",
    "le = LabelEncoder()\n",
    "le.fit(train_test[\"gearShifter\"].fill_null(\"\"))\n",
    "train = train.with_columns(\n",
    "    pl.Series(le.transform(train[\"gearShifter\"].fill_null(\"\"))).cast(pl.Int16).alias(\"gearShifter\")\n",
    ")\n",
    "test = test.with_columns(pl.Series(le.transform(test[\"gearShifter\"].fill_null(\"\"))).cast(pl.Int16).alias(\"gearShifter\"))\n",
    "train_test = pl.concat([train, test], how=\"diagonal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シーンごとのデータ数の分布 → 多くのシーンが3以上あるので2個前後の値の特徴量があってもいいと思う\n",
    "data = train_test.group_by(\"scene\").agg(pl.len()).get_column(\"len\")\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(data, bins=30)\n",
    "plt.xlabel(\"シーンごとのデータ数\")\n",
    "plt.ylabel(\"シーン数\")\n",
    "plt.title(\"シーンごとのデータ数の分布\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同一シーンからの集約特徴量作成\n",
    "\n",
    "agg_cols = [\"vEgo\", \"aEgo\", \"steeringAngleDeg\", \"steeringTorque\", \"gas\"]\n",
    "bool_cols = [\"brakePressed\", \"gasPressed\", \"leftBlinker\", \"rightBlinker\"]\n",
    "cat_cols = [\"gearShifter\"]\n",
    "\n",
    "exprs = []\n",
    "exprs += [\n",
    "    pl.col(agg_col).shift(-2).over(\"scene\").alias(f\"{agg_col}_shift-2\") for agg_col in agg_cols + bool_cols + cat_cols\n",
    "]  # 2ステップ前の時間の値\n",
    "exprs += [\n",
    "    pl.col(agg_col).shift(2).over(\"scene\").alias(f\"{agg_col}_shift2\") for agg_col in agg_cols + bool_cols + cat_cols\n",
    "]  # 2ステップ後の時間の値\n",
    "exprs += [\n",
    "    pl.col(agg_col).shift(-1).over(\"scene\").alias(f\"{agg_col}_shift-1\") for agg_col in agg_cols + bool_cols + cat_cols\n",
    "]  # 1ステップ前の時間の値\n",
    "exprs += [\n",
    "    pl.col(agg_col).shift(1).over(\"scene\").alias(f\"{agg_col}_shift1\") for agg_col in agg_cols + bool_cols + cat_cols\n",
    "]  # 1ステップ後の時間の値\n",
    "exprs += [\n",
    "    pl.col(agg_col).diff(-1).over(\"scene\").alias(f\"{agg_col}_diff-1\") for agg_col in agg_cols + bool_cols\n",
    "]  # 1ステップ前の時間の値との差分\n",
    "exprs += [\n",
    "    pl.col(agg_col).diff(1).over(\"scene\").alias(f\"{agg_col}_diff1\") for agg_col in agg_cols + bool_cols\n",
    "]  # 1ステップ後の時間の値との差分\n",
    "exprs += [pl.col(agg_col).mean().over(\"scene\").alias(f\"{agg_col}_mean\") for agg_col in agg_cols]  # 同一シーンの平均値\n",
    "exprs += [pl.col(agg_col).std().over(\"scene\").alias(f\"{agg_col}_std\") for agg_col in agg_cols]  # 同一シーンの標準偏差\n",
    "exprs += [pl.col(agg_col).max().over(\"scene\").alias(f\"{agg_col}_max\") for agg_col in agg_cols]  # 同一シーンの最大値\n",
    "exprs += [pl.col(agg_col).min().over(\"scene\").alias(f\"{agg_col}_min\") for agg_col in agg_cols]  # 同一シーンの最小値\n",
    "\n",
    "# train_test = train_test.sort(\n",
    "#     # shiftと diffが時系列順に並んでいる必要があるためシーンごとに時間軸でソート\n",
    "#     \"scene\",\n",
    "#     \"decisecond\",\n",
    "# ).with_columns(exprs)\n",
    "train = train.sort(\"scene\", \"decisecond\").with_columns(exprs)\n",
    "test = test.sort(\"scene\", \"decisecond\").with_columns(exprs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 信号機情報\n",
    "traffic_lights_dfs = []\n",
    "\n",
    "# 信号機情報が入っているjsonファイルを1件ずつ読み込む\n",
    "for f in tqdm(glob.glob(\"../../data/input/traffic_lights/*\"), smoothing=True):\n",
    "    if os.path.getsize(f) < 3:\n",
    "        # ファイルサイズが3未満（からのファイル）の場合はスキップ\n",
    "        # からのファイルはおそらく信号機が映っていない or 検出できなかったものと思われる\n",
    "        continue\n",
    "    data_id = f.split(\"/\")[-1].split(\".\")[0]\n",
    "    # jsonを読み込みフォルダ名からIDカラムを作成\n",
    "    traffic_lights_dfs.append(pl.read_json(f).with_columns(pl.lit(data_id).alias(\"ID\")))\n",
    "\n",
    "# jsonから作成した個別のDataFrameを結合\n",
    "traffic_lights_df = pl.concat(traffic_lights_dfs, how=\"vertical\")\n",
    "# bboxがListになっているので列に展開\n",
    "bbox_df = traffic_lights_df[\"bbox\"].list.to_struct(fields=[f\"bbox_{i}\" for i in range(4)]).struct.unnest()\n",
    "traffic_lights_df = pl.concat([traffic_lights_df, bbox_df], how=\"horizontal\").select(pl.all().exclude(\"bbox\"))\n",
    "traffic_lights_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classの数を集計\n",
    "traffic_lights_class_count_df = traffic_lights_df.pivot(\n",
    "    values=\"class\", index=\"ID\", on=\"class\", aggregate_function=\"len\"\n",
    ").fill_null(0)\n",
    "traffic_lights_class_count_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 信号機情報をtrainとtestに追加\n",
    "train = train.join(traffic_lights_class_count_df, how=\"left\", on=\"ID\")\n",
    "test = test.join(traffic_lights_class_count_df, how=\"left\", on=\"ID\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 信号機の位置情報を活用した特徴量\n",
    "train = train.with_columns(\n",
    "    [\n",
    "        # 信号機の検出数と車速の組み合わせ\n",
    "        (pl.col(\"green\") * pl.col(\"vEgo\")).alias(\"green_light_speed\"),\n",
    "        (pl.col(\"red\") * pl.col(\"vEgo\")).alias(\"red_light_speed\"),\n",
    "        # 信号機の総検出数\n",
    "        (pl.sum_horizontal([\"green\", \"red\", \"yellow\"])).alias(\"total_traffic_lights\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test = test.with_columns(\n",
    "    [\n",
    "        # 信号機の検出数と車速の組み合わせ\n",
    "        (pl.col(\"green\") * pl.col(\"vEgo\")).alias(\"green_light_speed\"),\n",
    "        (pl.col(\"red\") * pl.col(\"vEgo\")).alias(\"red_light_speed\"),\n",
    "        # 信号機の総検出数\n",
    "        (pl.sum_horizontal([\"green\", \"red\", \"yellow\"])).alias(\"total_traffic_lights\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 元の順序に戻す\n",
    "train = train.sort(\"index\")\n",
    "test = test.sort(\"index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train.columns), len(test.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_cols = [\"ID\", \"scene\", \"decisecond\", \"index\", \"brake\"] + cfg.target_cols\n",
    "use_cols = list(set(train.columns) - set(del_cols))\n",
    "use_cols.sort()\n",
    "\n",
    "group_cols = [\"scene\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.select(use_cols).to_pandas()\n",
    "group = train.select(group_cols).to_pandas()\n",
    "x_test = test.select(use_cols).to_pandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習関数\n",
    "def lgb_cv_train(x_train, y_train, group):\n",
    "    # 学習設定\n",
    "    lgb_data = lgb.Dataset(\n",
    "        x_train,\n",
    "        label=y_train,\n",
    "        # categorical_feature=cfg.categorical_features,\n",
    "    )\n",
    "    callbacks = [\n",
    "        lgb.early_stopping(stopping_rounds=cfg.lgb.early_stopping_rounds),\n",
    "        lgb.log_evaluation(cfg.lgb.log_evaluation_period),\n",
    "    ]\n",
    "\n",
    "    # 学習\n",
    "    cv_results = lgb.cv(\n",
    "        dict(cfg.lgb.params),\n",
    "        lgb_data,\n",
    "        folds=gkf.split(x_train, y_train, group),\n",
    "        num_boost_round=cfg.lgb.num_boost_round,\n",
    "        callbacks=callbacks,\n",
    "        return_cvbooster=True,\n",
    "        seed=cfg.seed,\n",
    "    )\n",
    "\n",
    "    return cv_results\n",
    "\n",
    "\n",
    "# log 関数\n",
    "def log_cv_results(cv_results, target_col):\n",
    "    cvbooster = cv_results[\"cvbooster\"]\n",
    "    best_iteration = cvbooster.best_iteration\n",
    "    best_score = cv_results[\"valid l1-mean\"][best_iteration - 1]\n",
    "    best_score_stdv = cv_results[\"valid l1-stdv\"][best_iteration - 1]\n",
    "\n",
    "    with open(f\"{cfg.data.results_path}/{target_col}/log.txt\", \"w\") as log_file:\n",
    "        log_file.write(\"====== CV Score ======\\n\")\n",
    "        log_file.write(f\"best_iteration: {best_iteration}\\n\")\n",
    "        log_file.write(f\"best_score: {best_score}\\n\")\n",
    "        log_file.write(f\"best_score_stdv: {best_score_stdv}\\n\")\n",
    "\n",
    "        log_file.write(\"\\n====== params ======\\n\")\n",
    "        log_file.write(OmegaConf.to_yaml(cfg, resolve=True))\n",
    "\n",
    "        log_file.write(\"\\n====== feature name ======\\n\")\n",
    "        log_file.write(pprint.pformat(cvbooster.feature_name()[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実験結果格納用のディレクトリを作成\n",
    "japan_tz = pytz.timezone(\"Asia/Tokyo\")\n",
    "cfg.run_time = datetime.now(japan_tz).strftime(\"%Y%m%d_%H%M%S\")\n",
    "create_dir(cfg.data.results_path)\n",
    "\n",
    "# cv, predsリスト\n",
    "cv_scores = []\n",
    "target_preds = []\n",
    "\n",
    "for target_col in cfg.target_cols:\n",
    "    print(f\"\\n\\n===== target_col: {target_col} =====\\n\\n\")\n",
    "    y_train = train.select(target_col).to_pandas()\n",
    "    # 学習\n",
    "    cv_results = lgb_cv_train(x_train, y_train, group)\n",
    "\n",
    "    # 学習モデル保存\n",
    "    cvbooster = cv_results[\"cvbooster\"]\n",
    "    create_dir(f\"{cfg.data.results_path}/{target_col}\")\n",
    "    with open(f\"{cfg.data.results_path}/{target_col}/model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(cvbooster, f)\n",
    "\n",
    "    # log\n",
    "    log_cv_results(cv_results, target_col)\n",
    "\n",
    "    # CV用のスコアを保存\n",
    "    best_iteration = cv_results[\"cvbooster\"].best_iteration\n",
    "    best_score = cv_results[\"valid l1-mean\"][best_iteration - 1]\n",
    "    cv_scores.append(best_score)\n",
    "\n",
    "    # テストコードの推論\n",
    "    x_test = test.select(use_cols).to_pandas()\n",
    "    y_preds = cvbooster.predict(x_test, num_iteration=cvbooster.best_iteration)\n",
    "    y_pred = np.mean(y_preds, axis=0)\n",
    "    target_preds.append(y_pred)\n",
    "\n",
    "# # モデルのロード\n",
    "# with open(f\"{cfg.data.results_path}/model.pkl\", \"rb\") as f:\n",
    "#     loaded_cvbooster = pickle.load(f)\n",
    "\n",
    "# cv_score\n",
    "cv_score = np.mean(cv_scores)\n",
    "print(f\"cv_score: {cv_score}\")\n",
    "\n",
    "# submission\n",
    "exprs = [pl.Series(target_preds[i]).alias(cfg.target_cols[i]) for i in range(len(cfg.target_cols))]\n",
    "submission = sample_submission.with_columns(exprs)\n",
    "submission.write_csv(f\"{cfg.data.results_path}/submission_{cv_score:.4f}.csv\")\n",
    "submission.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
